{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94f8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "506afafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.resnet import ResNet\n",
    "# from typing_extensions import Required\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from util import load_az_dataset\n",
    "from util import load_zero_nine_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bad35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -a AZ -m MODEL [-p PLOT]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -a/--az, -m/--model\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "\n",
    "ap.add_argument(\"-a\", \"--az\", required=True, help=\"path to A-Z dataset\")\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
    "                help=\"path to output the trained handwriting recognition model\")\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "                help=\"path to output the training history file\")\n",
    "\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea462ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading datasets...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e3160213e44d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] loading datasets...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mazData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mazLabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_az_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"az\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdigitsData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigitsLabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_zero_nine_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\MY_PROJECTS\\Car-License-Plate-Recognition\\util.py\u001b[0m in \u001b[0;36mload_az_dataset\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# loop over the rows of the A-Z handwritten digit dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# parse the label and image from the row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-1\n",
    "BS = 128\n",
    "\n",
    "# load the A-Z and MNIST datasets, respectively\n",
    "print(\"[INFO] loading datasets...\")\n",
    "\n",
    "(azData, azLabels) = load_az_dataset(args[\"az\"])\n",
    "(digitsData, digitsLabels) = load_zero_nine_dataset()\n",
    "\n",
    "# the MNIST dataset occupies the labels 0-9, so let's add 10 to every\n",
    "# A-Z label to ensure the A-Z characters are not incorrectly labeled\n",
    "# as digits\n",
    "azLabels += 10\n",
    "\n",
    "\n",
    "# stack the A-Z data and labels with the MNIST digits data and labels\n",
    "data = np.vstack([azData, digitsData])\n",
    "labels = np.hstack([azLabels, digitsLabels])\n",
    "\n",
    "# each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
    "# however, the architecture we're using is designed for 32x32 images,\n",
    "# so we need to resize them to 32x32\n",
    "data = [cv2.resize(image, (32, 32)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "\n",
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= 255.0\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "le = LabelBinarizer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
